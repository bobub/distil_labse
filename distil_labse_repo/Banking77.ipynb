{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448cc67a",
   "metadata": {},
   "source": [
    "## Banking77 Task\n",
    "This script trains a topic classifier for the banking77 task. The task it to correctly categorise the customer query to the correct type of query, given by the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c699ee9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9192,
     "status": "ok",
     "timestamp": 1623672586834,
     "user": {
      "displayName": "Boris Bubla",
      "photoUrl": "",
      "userId": "03511421439649827085"
     },
     "user_tz": -120
    },
    "id": "SpBdN6nRXgoC",
    "outputId": "30d1afd5-193d-450a-ffe7-385ffd557a8e"
   },
   "outputs": [],
   "source": [
    "# Installs\n",
    "\n",
    "# !pip install transformers\n",
    "!pip uninstall scikit-learn -y\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94360d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3655,
     "status": "ok",
     "timestamp": 1623683485785,
     "user": {
      "displayName": "Boris Bubla",
      "photoUrl": "",
      "userId": "03511421439649827085"
     },
     "user_tz": -120
    },
    "id": "319bcf30-f550-4555-9ba0-708ff6373b96",
    "outputId": "4147dd0c-d07a-4691-a854-91c5d8c6e54d"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from os import environ\n",
    "from psutil import cpu_count\n",
    "from contextlib import contextmanager\n",
    "from dataclasses import dataclass\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from distil_funcs import *\n",
    "from utils import load_csv, read_torch\n",
    "\n",
    "# Load Tokeniser\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "train_path = \"data/banking77/train.csv\"\n",
    "test_path = 'data/banking77/test.csv'\n",
    "\n",
    "# Load data\n",
    "en_train_data = pd.read_csv(train_path).sample(frac=1, random_state=1)\n",
    "en_train_tokenized = tokenizer(en_train_data.text.to_list(), padding=True, truncation=True, max_length=64, return_tensors='pt')\n",
    "en_train_labels = en_train_data.category.to_list()\n",
    "\n",
    "en_test_data = pd.read_csv(test_path)\n",
    "en_test_tokenized = tokenizer(en_test_data.text.to_list(), padding=True, truncation=True, max_length=64, return_tensors='pt')\n",
    "en_test_labels = en_test_data.category.to_list()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions for pipeline\n",
    "\n",
    "# Creates sentence embeddings from a given input text using the given model\n",
    "def get_embeddings_torch(model, input_text):\n",
    "    data_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(input_text['input_ids'], input_text['token_type_ids'], input_text['attention_mask']), batch_size=64)\n",
    "    results = []\n",
    "    for step, batch in enumerate(tqdm(data_loader, position=0, leave=True)):\n",
    "        encoded_slice_dict =  {\n",
    "            'input_ids': batch[0],\n",
    "            'token_type_ids': batch[1],\n",
    "            'attention_mask': batch[2]\n",
    "        }\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_slice_dict)\n",
    "        embeddings = model_output['pooler_output']\n",
    "        embeddings = torch.nn.functional.normalize(embeddings)\n",
    "        results = results + list(embeddings)\n",
    "    \n",
    "    results = torch.stack((results))\n",
    "    return results\n",
    "\n",
    "# Performs the benchmark test - fits a LogisticRegressionCV model, predicts the labels, \n",
    "# prints classification report and saves the result to a csv file\n",
    "def benchmark_banking77(train_embeddings, test_embeddings, model_name):\n",
    "\n",
    "    # build classifier based on those embeddings\n",
    "    classifier_model = LogisticRegressionCV(cv=4, max_iter=10000)\n",
    "    classifier_model.fit(X=train_embeddings, y=en_train_labels)\n",
    "    print(\"Classifier model built...\")\n",
    "    \n",
    "    # generate predictions\n",
    "    en_predictions = classifier_model.predict(test_embeddings)\n",
    "    print(\"Predictions generated...\")\n",
    "    \n",
    "    # print classification results\n",
    "    print(\"Banking77 Results: \\n\")\n",
    "    report = classification_report(en_test_labels, en_predictions)\n",
    "    print(report)\n",
    "    dict_report = classification_report(en_test_labels, en_predictions, output_dict=True)\n",
    "    df = pd.DataFrame.from_dict(dict_report).T.round(2)\n",
    "    df.to_csv('classification_report_{}.csv'.format(model_name), index = True)\n",
    "    print('Classification report saved!')\n",
    "    \n",
    "print(\"Banking77 loaded!\")\n",
    "\n",
    "# Save any generated embeddings using joblib\n",
    "def save_embeddings(embeddings, labels, name):\n",
    "    # save embeddings\n",
    "    filename = \"data/banking77/embeddings_\" + name\n",
    "    joblib.dump(embeddings, Path(filename + \".joblib\"))\n",
    "    joblib.dump(labels, Path(filename + \"_labels.joblib\"))\n",
    "    print(\"Files saved at prefix: \" + filename + \"...\")\n",
    "\n",
    "# Load any previous embeddings\n",
    "def load_embeddings(name):\n",
    "    # save embeddings\n",
    "    filename = \"data/banking77/embeddings_\" + name\n",
    "    embeddings = joblib.load(Path(filename + \".joblib\"))\n",
    "    labels = joblib.load(Path(filename + \"_labels.joblib\"))\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf93ed",
   "metadata": {
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1623683248793,
     "user": {
      "displayName": "Boris Bubla",
      "photoUrl": "",
      "userId": "03511421439649827085"
     },
     "user_tz": -120
    },
    "id": "RS9l3YPzCqM_"
   },
   "outputs": [],
   "source": [
    "# Load Teacher Model for Evaluation\n",
    "DEVICE = torch.device('cpu')\n",
    "teacher_model = load_teacher(DEVICE)\n",
    "\n",
    "student_config = {\n",
    "    'd_model': 768, # hidden dim of model\n",
    "    'heads': 12, # attention heads\n",
    "    'dropout':0.1, # dropout in network except ffn\n",
    "    'dropout_ffn':0.4, # dropout in ffn \n",
    "    'd_ff': 96, # num features in FFN hidden layer\n",
    "    'n_layers': 2, # num of transformer layers\n",
    "    'n_experts': 40, # number of FFN experts\n",
    "    'load_balancing_loss_ceof': 0.01, # load balancing co-eff, encourages expert diversity\n",
    "    'is_scale_prob': True, # whether to scale the selected expert outputs by routing probability\n",
    "    'drop_tokens': False, # whether to drop tokens\n",
    "    'capacity_factor':1.25, # capacity factor - seemed to work best in Switch Transformer\n",
    "}\n",
    "\n",
    "# 3. Create student model\n",
    "word_embeddings = deepcopy(teacher_model.get_input_embeddings())\n",
    "compressed_word_embeddings = word_embedding_compression(word_embeddings, student_config['d_model'])\n",
    "student_model = LaBSE_Switch(config=student_config, word_embeddings_module=compressed_word_embeddings)\n",
    "\n",
    "# 4. Load state_dict() of trained student\n",
    "path = 's3://eu1-sagemaker-bucket/borisbubla/experiments/10000.0k/switch/LR0.0005LAY2EXP40D_FF96TEMP9TIME-20210609-174240/Distil_LaBSE_2L_40E_96D'\n",
    "file = read_torch(path)\n",
    "student_model.load_state_dict(file)\n",
    "student_model.eval()\n",
    "# path = '/home/ec2-user/SageMaker/models/switch/time-20210611-133301/model_200.pkl'\n",
    "# checkpoint = torch.load(path, map_location = torch.device('cpu'))\n",
    "# student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# student_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df521e0",
   "metadata": {
    "id": "28bb919e-dcc7-4400-ab14-fd9e2cb5c89f"
   },
   "source": [
    "### Banking77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668929fb",
   "metadata": {},
   "source": [
    "#### 1. Create or Load Embeddings - teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac05b2",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1623683250936,
     "user": {
      "displayName": "Boris Bubla",
      "photoUrl": "",
      "userId": "03511421439649827085"
     },
     "user_tz": -120
    },
    "id": "_JPpbyAaDTAw"
   },
   "outputs": [],
   "source": [
    "# create embeddings OR load embeddings\n",
    "\n",
    "# create \n",
    "labse_embeddings_train = get_embeddings_torch(model=teacher_model, input_text=en_train_tokenized)\n",
    "labse_embeddings_test = get_embeddings_torch(model=teacher_model, input_text=en_test_tokenized)\n",
    "\n",
    "# save\n",
    "save_embeddings(labse_embeddings_train, en_train_labels, 'banking77_train')\n",
    "save_embeddings(labse_embeddings_test, en_test_labels, 'banking77_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfab22ae",
   "metadata": {
    "id": "PF5ohW2CZVPk"
   },
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "labse_embeddings_train, en_train_labels = load_embeddings('banking77_train')\n",
    "labse_embeddings_test, en_test_labels = load_embeddings('banking77_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e454d",
   "metadata": {},
   "source": [
    "#### 2. Do benchmark - teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebec608",
   "metadata": {
    "id": "EunqaaPYZrmF"
   },
   "outputs": [],
   "source": [
    "# do benchmark\n",
    "benchmark_banking77(labse_embeddings_train, labse_embeddings_test, 'labse_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d791d",
   "metadata": {},
   "source": [
    "#### 3. Create or load embeddings - student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a914cda1",
   "metadata": {
    "id": "pps0emlDbFlQ"
   },
   "outputs": [],
   "source": [
    "# create or load embeddings\n",
    "\n",
    "# create\n",
    "distil_labse_embeddings_train = get_embeddings_torch(model=student_model, input_text=en_train_tokenized)\n",
    "distil_labse_embeddings_test = get_embeddings_torch(model=student_model, input_text=en_test_tokenized)\n",
    "\n",
    "# save\n",
    "save_embeddings(distil_labse_embeddings_train, en_train_labels, 'distil_40E96D_banking77_train')\n",
    "save_embeddings(distil_labse_embeddings_test, en_test_labels, 'distil_40E96D_banking77_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "050707fa",
   "metadata": {
    "id": "81b1fd67-1e86-4ecf-b927-c91a75eaebc5"
   },
   "outputs": [],
   "source": [
    "# load \n",
    "distil_labse_embeddings_train, en_train_labels = load_embeddings('distil_40E96D_banking77_train')\n",
    "distil_labse_embeddings_test, en_test_labels = load_embeddings('distil_40E96D_banking77_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5dc359",
   "metadata": {},
   "source": [
    "#### 4. Do benchmark - student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0114e784",
   "metadata": {
    "id": "YRuJPTjIamMH"
   },
   "outputs": [],
   "source": [
    "# do benchmark\n",
    "benchmark_banking77(distil_labse_embeddings_train, distil_labse_embeddings_test, 'distil_labse_2L_40E_96D')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17220a3",
   "metadata": {},
   "source": [
    "#### 5. Sanity check - print cosine_similarity scores of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a7d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "print('Average CosSim for these embeddings: ',np.diag(cosine_similarity(labse_embeddings_train, distil_labse_embeddings_train)).mean())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Banking77.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
